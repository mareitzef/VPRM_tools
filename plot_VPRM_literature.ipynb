{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'VPRM_all_params_literature_old_no_callewaert.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m run_ID3_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt. NNSE + no PAR conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# run_ID4 = \"diff_evo_V4_100\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# run_ID4_str = \"original version\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVPRM_all_params_literature_old_no_callewaert.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     18\u001b[0m tables \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/c7071034/conda_envs/py_basic/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'VPRM_all_params_literature_old_no_callewaert.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "\n",
    "VPRM_old_or_new = \"old\"\n",
    "run_ID = \"diff_evo_V7_100\"\n",
    "run_ID_str = \"Topt_min=0\"\n",
    "run_ID2 = \"diff_evo_V10_100\"\n",
    "run_ID2_str = \"Topt lb = calculated\"\n",
    "run_ID3 = \"diff_evo_V23_42\"\n",
    "run_ID3_str = \"opt. NNSE + no PAR conversion\"\n",
    "# run_ID4 = \"diff_evo_V4_100\"\n",
    "# run_ID4_str = \"original version\"\n",
    "\n",
    "with open(\"VPRM_all_params_literature_old_no_callewaert.csv\", \"r\") as file:\n",
    "    data = file.read()\n",
    "tables = data.split(\"\\n\\n\")\n",
    "\n",
    "df_tuned_alps_outs = []\n",
    "nr_of_tables = 0\n",
    "for table in tables:\n",
    "    if not table.strip():  # Skip empty tables\n",
    "        continue\n",
    "    df = pd.read_csv(StringIO(table))\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    dfs.append(df)\n",
    "    nr_of_tables += 1\n",
    "for df in dfs:\n",
    "    df.sort_index(axis=1, inplace=True)\n",
    "\n",
    "df_tuned_alps = pd.read_csv(\"Alps_parameters_median_old_Alps_VPRM_optimized_params_\"+run_ID+\".csv\")\n",
    "df_tuned_alps.drop(index=df_tuned_alps[df_tuned_alps['Parameter'] == 'Topt'].index, inplace=True)\n",
    "df_tuned_alps['Parameter'] = df_tuned_alps['Parameter'].replace({'lambd': 'lambda'})\n",
    "df_tuned_alps.loc[df_tuned_alps['Parameter'] == 'lambda', df_tuned_alps.columns != 'Parameter'] *= -1 #-0.505 # be aware that the values of Î» and P AR0 might need to be adjusted when copying parameter values from literature since some studies use P AR = SW/0.505, while in the model code P AR = SW\n",
    "df_tuned_alps.loc[df_tuned_alps['Parameter'] == 'PAR0', df_tuned_alps.columns != 'Parameter'] #*= 0.505\n",
    "df_tuned_alps.set_index(df_tuned_alps.columns[0], inplace=True)\n",
    "df_tuned_alps.sort_index(axis=1, inplace=True)\n",
    "\n",
    "df_tuned_alps2 = pd.read_csv(\"Alps_parameters_median_old_Alps_VPRM_optimized_params_\"+run_ID2+\".csv\")\n",
    "df_tuned_alps2.drop(index=df_tuned_alps2[df_tuned_alps2['Parameter'] == 'Topt'].index, inplace=True)\n",
    "df_tuned_alps2['Parameter'] = df_tuned_alps2['Parameter'].replace({'lambd': 'lambda'})\n",
    "df_tuned_alps2.loc[df_tuned_alps2['Parameter'] == 'lambda', df_tuned_alps2.columns != 'Parameter'] *= -1 #-0.505\n",
    "df_tuned_alps2.loc[df_tuned_alps2['Parameter'] == 'PAR0', df_tuned_alps2.columns != 'Parameter'] #*= 0.505\n",
    "df_tuned_alps2.set_index(df_tuned_alps2.columns[0], inplace=True)\n",
    "df_tuned_alps2.sort_index(axis=1, inplace=True)\n",
    "\n",
    "df_tuned_alps3 = pd.read_csv(\"Alps_parameters_median_old_Alps_VPRM_optimized_params_\"+run_ID3+\".csv\")\n",
    "df_tuned_alps3.drop(index=df_tuned_alps3[df_tuned_alps3['Parameter'] == 'Topt'].index, inplace=True)\n",
    "df_tuned_alps3['Parameter'] = df_tuned_alps3['Parameter'].replace({'lambd': 'lambda'})\n",
    "df_tuned_alps3.loc[df_tuned_alps3['Parameter'] == 'lambda', df_tuned_alps3.columns != 'Parameter'] *= -1 #-0.505\n",
    "df_tuned_alps3.loc[df_tuned_alps3['Parameter'] == 'PAR0', df_tuned_alps3.columns != 'Parameter'] #*= 0.505\n",
    "df_tuned_alps3.set_index(df_tuned_alps3.columns[0], inplace=True)\n",
    "df_tuned_alps3.sort_index(axis=1, inplace=True)\n",
    "\n",
    "params = ['PAR0', 'lambda', 'alpha', 'beta']\n",
    "colors = sns.color_palette(\"husl\", len(dfs))\n",
    "markers = ['o', 's', '^', 'D', 'P', 'X', 'p', 'H', 'v']\n",
    "\n",
    "font_size = 14\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 8))  # Increase width of plots\n",
    "\n",
    "for i, (param, ax) in enumerate(zip(params, axes.flat)):\n",
    "    for j, (df, marker) in enumerate(zip(dfs, markers)):\n",
    "        citation_name = df.index.name\n",
    "        ax.scatter(df.columns, df.loc[param], marker=marker, label=citation_name, color=colors[j] ,linewidth=1)\n",
    "        ax.grid(True)\n",
    "    # Plot df_tuned_alps using thick black horizontal line as a marker\n",
    "    ax.scatter(df_tuned_alps.columns, df_tuned_alps.loc[param], marker='*', color='red', label=run_ID_str, linewidth=5)  # Increase linewidth for df_tuned_alps\n",
    "    ax.scatter(df_tuned_alps2.columns, df_tuned_alps2.loc[param], marker='*', color='black', label=run_ID2_str, linewidth=5)  # Increase linewidth for df_tuned_alps\n",
    "    ax.scatter(df_tuned_alps3.columns, df_tuned_alps3.loc[param], marker='*', color='green', label=run_ID3_str, linewidth=5)  # Increase linewidth for df_tuned_alps\n",
    "    ax.set_title(param, fontsize=font_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "# Add a legend on the right side\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"compare_params_to_literature_Topt_defined_\"\n",
    "    + VPRM_old_or_new\n",
    "    + \"_\"\n",
    "    + run_ID\n",
    "    + \".eps\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENF</th>\n",
       "      <th>DBF</th>\n",
       "      <th>MF</th>\n",
       "      <th>SHB</th>\n",
       "      <th>SAV</th>\n",
       "      <th>CRO</th>\n",
       "      <th>GRA</th>\n",
       "      <th>NON</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PAR0</th>\n",
       "      <td>316.959342</td>\n",
       "      <td>310.777956</td>\n",
       "      <td>428.824566</td>\n",
       "      <td>363.0000</td>\n",
       "      <td>682.0000</td>\n",
       "      <td>595.856573</td>\n",
       "      <td>406.275695</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda</th>\n",
       "      <td>-0.304472</td>\n",
       "      <td>-0.215909</td>\n",
       "      <td>-0.144240</td>\n",
       "      <td>-0.0874</td>\n",
       "      <td>-0.1141</td>\n",
       "      <td>-0.139570</td>\n",
       "      <td>-0.448322</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.248510</td>\n",
       "      <td>0.170438</td>\n",
       "      <td>0.123981</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.259913</td>\n",
       "      <td>0.402375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>1.192070</td>\n",
       "      <td>1.614536</td>\n",
       "      <td>2.553547</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.227500</td>\n",
       "      <td>1.416304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topt</th>\n",
       "      <td>14.250000</td>\n",
       "      <td>23.580000</td>\n",
       "      <td>17.440000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ENF         DBF          MF       SHB       SAV         CRO  \\\n",
       "Parameter                                                                       \n",
       "PAR0       316.959342  310.777956  428.824566  363.0000  682.0000  595.856573   \n",
       "lambda      -0.304472   -0.215909   -0.144240   -0.0874   -0.1141   -0.139570   \n",
       "alpha        0.248510    0.170438    0.123981    0.0239    0.0049    0.259913   \n",
       "beta         1.192070    1.614536    2.553547    0.0000    0.0000    1.227500   \n",
       "Topt        14.250000   23.580000   17.440000   20.0000   20.0000   22.000000   \n",
       "\n",
       "                  GRA  NON  \n",
       "Parameter                   \n",
       "PAR0       406.275695  0.0  \n",
       "lambda      -0.448322  0.0  \n",
       "alpha        0.402375  0.0  \n",
       "beta         1.416304  0.0  \n",
       "Topt        15.880000  0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DataFrame and set index\n",
    "df_tuned_alps_out = pd.read_csv(\"Alps_parameters_median_old_Alps_VPRM_optimized_params_\" + run_ID3 + \".csv\")\n",
    "df_tuned_alps_out['Parameter'] = df_tuned_alps_out['Parameter'].replace({'lambd': 'lambda'})\n",
    "df_tuned_alps_out.set_index(\"Parameter\", inplace=True)\n",
    "\n",
    "# Reorder and filter rows as required\n",
    "desired_rows = ['PAR0', 'lambda', 'alpha', 'beta', 'Topt']\n",
    "df_tuned_alps_out = df_tuned_alps_out.loc[desired_rows]\n",
    "\n",
    "# Apply conversions\n",
    "df_tuned_alps_out.loc['PAR0'] # *= 0.505  # Conversion for PAR0 -> TODO find out units, i think it needs no conversion\n",
    "df_tuned_alps_out.loc['lambda'] *= -1  # Conversion for lambd\n",
    "\n",
    "# Add values for SHB, SAV, and fill missing values with 0\n",
    "df_tuned_alps_out[\"SAV\"] = dfs[0].get(\"SAV\", 0)\n",
    "df_tuned_alps_out[\"SHB\"] = dfs[0].get(\"SHB\", 0)\n",
    "df_tuned_alps_out[\"NON\"] = 0.0\n",
    "\n",
    "# Reorder columns as needed\n",
    "desired_cols = ['ENF', 'DBF', 'MF', 'SHB', 'SAV', 'CRO', 'GRA', \"NON\"]\n",
    "df_tuned_alps_out = df_tuned_alps_out[desired_cols]\n",
    "\n",
    "# Fill missing values in the entire DataFrame with 0\n",
    "df_tuned_alps_out = df_tuned_alps_out.fillna(20)\n",
    "\n",
    "# Save the DataFrame to CSV with 3 decimal precision\n",
    "df_tuned_alps_out.to_csv(\"parameters_for_WRF.csv\", float_format='%.3f')\n",
    "\n",
    "# Display the DataFrame\n",
    "df_tuned_alps_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written as vprm_table_multi_eu.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Format the data as required\n",
    "formatted_data = (\n",
    "    \"DATA vprm_table_multi_eu &\\n\"\n",
    "    \"     / \"\n",
    "    + \", \".join(f\"{value:.3f}\" for value in df_tuned_alps_out.loc[\"PAR0\"]) + \", &\\n\"\n",
    "    \"      \"\n",
    "    + \", \".join(f\"{value:.3f}\" for value in df_tuned_alps_out.loc[\"lambda\"]) + \", &\\n\"\n",
    "    \"      \"\n",
    "    + \", \".join(f\"{value:.3f}\" for value in df_tuned_alps_out.loc[\"alpha\"]) + \", &\\n\"\n",
    "    \"      \"\n",
    "    + \", \".join(f\"{value:.3f}\" for value in df_tuned_alps_out.loc[\"beta\"]) + \", &\\n\"\n",
    "    \"      \"\n",
    "    + \", \".join(f\"{value:.3f}\" for value in df_tuned_alps_out.loc[\"Topt\"]) + \" /\"\n",
    ")\n",
    "\n",
    "# Save to a text file\n",
    "with open(\"vprm_table_multi_eu.csv\", \"w\") as file:\n",
    "    file.write(formatted_data)\n",
    "\n",
    "print(\"File written as vprm_table_multi_eu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from io import StringIO\n",
    "\n",
    "# VPRM_old_or_new = \"old\"\n",
    "# run_ID = \"diff_evo_V10_100\"\n",
    "\n",
    "# with open(\"VPRM_all_params_literature_old_no_callewaert.csv\", \"r\") as file:\n",
    "#     data = file.read()\n",
    "# tables = data.split(\"\\n\\n\")\n",
    "\n",
    "# dfs = []\n",
    "# nr_of_tables = 0\n",
    "# for table in tables:\n",
    "#     if not table.strip():  # Skip empty tables\n",
    "#         continue\n",
    "#     df = pd.read_csv(StringIO(table))\n",
    "#     df.set_index(df.columns[0], inplace=True)\n",
    "#     dfs.append(df)\n",
    "#     nr_of_tables += 1\n",
    "# for df in dfs:\n",
    "#     df.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# df_tuned_alps = pd.read_csv(\"Alps_parameters_median_old_Alps_VPRM_optimized_params_\"+run_ID+\".csv\")\n",
    "# df_tuned_alps.drop(index=df_tuned_alps[df_tuned_alps['Parameter'] == 'Topt'].index, inplace=True)\n",
    "# df_tuned_alps['Parameter'] = df_tuned_alps['Parameter'].replace({'lambd': 'lambda'})\n",
    "# df_tuned_alps.loc[df_tuned_alps['Parameter'] == 'lambda', df_tuned_alps.columns != 'Parameter'] *= -1\n",
    "# df_tuned_alps.set_index(df_tuned_alps.columns[0], inplace=True)\n",
    "# df_tuned_alps.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# df_tuned_alps2 = pd.read_csv(\"Europe_parameters_median_old_Europe_VPRM_optimized_params_\"+run_ID+\".csv\")\n",
    "# df_tuned_alps2.drop(index=df_tuned_alps2[df_tuned_alps2['Parameter'] == 'Topt'].index, inplace=True)\n",
    "# df_tuned_alps2['Parameter'] = df_tuned_alps2['Parameter'].replace({'lambd': 'lambda'})\n",
    "# df_tuned_alps2.loc[df_tuned_alps2['Parameter'] == 'lambda', df_tuned_alps2.columns != 'Parameter'] *= -1\n",
    "# df_tuned_alps2.set_index(df_tuned_alps2.columns[0], inplace=True)\n",
    "# df_tuned_alps2.sort_index(axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# params = ['PAR0', 'lambda', 'alpha', 'beta']\n",
    "# colors = sns.color_palette(\"husl\", len(dfs))\n",
    "# markers = ['o', 's', '^', 'D', 'P', 'X', 'p', 'H', 'v']\n",
    "\n",
    "# font_size = 14\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 8))  # Increase width of plots\n",
    "\n",
    "# for i, (param, ax) in enumerate(zip(params, axes.flat)):\n",
    "#     for j, (df, marker) in enumerate(zip(dfs, markers)):\n",
    "#         citation_name = df.index.name\n",
    "#         ax.scatter(df.columns, df.loc[param], marker=marker, label=citation_name, color=colors[j])\n",
    "#         ax.grid(True)\n",
    "#     # Plot df_tuned_alps using thick black horizontal line as a marker\n",
    "#     ax.scatter(df_tuned_alps.columns, df_tuned_alps.loc[param], marker='*', color='black', label='alps_R24', linewidth=2)  # Increase linewidth for df_tuned_alps\n",
    "#     ax.scatter(df_tuned_alps2.columns, df_tuned_alps2.loc[param], marker='*', color='red', label='europe_R24', linewidth=2)  # Increase linewidth for df_tuned_alps\n",
    "#     ax.set_title(param, fontsize=font_size)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "# # Add a legend on the right side\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=font_size)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     \"compare_params_to_literature_\"\n",
    "#     + VPRM_old_or_new\n",
    "#     + \"_\"\n",
    "#     + run_ID\n",
    "#     + \".eps\",\n",
    "#     dpi=300,\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from io import StringIO\n",
    "\n",
    "# VPRM_old_or_new = \"new\"\n",
    "# # run_ID = \"diff_evo_V9_100\"\n",
    "\n",
    "# with open(\"VPRM_all_params_literature_\"+VPRM_old_or_new+\".csv\", \"r\") as file:\n",
    "#     data = file.read()\n",
    "# tables = data.split(\"\\n\\n\")\n",
    "\n",
    "# dfs = []\n",
    "# nr_of_tables = 0\n",
    "# for table in tables:\n",
    "#     if not table.strip():  # Skip empty tables\n",
    "#         continue\n",
    "#     df = pd.read_csv(StringIO(table))\n",
    "#     df.set_index(df.columns[0], inplace=True)\n",
    "#     dfs.append(df)\n",
    "#     nr_of_tables += 1\n",
    "# for df in dfs:\n",
    "#     df.sort_index(axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "# # Alps_parameters_mean_new_Alps_VPRM_optimized_params_diff_evo_V4_100\n",
    "# # Alps_parameters_mean_new_Europe_VPRM_optimized_params_diff_evo_V4_100.csv'\n",
    "\n",
    "# df_tuned_alps = pd.read_csv(\"Alps_parameters_median_\"+VPRM_old_or_new+\"_Alps_VPRM_optimized_params_\"+run_ID+\".csv\")\n",
    "# #df_tuned_alps.drop(index=df_tuned_alps[df_tuned_alps['Parameter'] == 'Topt'].index, inplace=True)\n",
    "# df_tuned_alps['Parameter'] = df_tuned_alps['Parameter'].replace({'lambd': 'lambda'})\n",
    "# df_tuned_alps.loc[df_tuned_alps['Parameter'] == 'lambda', df_tuned_alps.columns != 'Parameter'] *= -1\n",
    "# df_tuned_alps.set_index(df_tuned_alps.columns[0], inplace=True)\n",
    "# df_tuned_alps.sort_index(axis=1, inplace=True)\n",
    "# #\n",
    "# df_tuned_alps2 = pd.read_csv(\"Europe_parameters_median_\"+VPRM_old_or_new+\"_Europe_VPRM_optimized_params_\"+run_ID+\".csv\")\n",
    "# #df_tuned_alps2.drop(index=df_tuned_alps2[df_tuned_alps2['Parameter'] == 'Topt'].index, inplace=True)\n",
    "# df_tuned_alps2['Parameter'] = df_tuned_alps2['Parameter'].replace({'lambd': 'lambda'})\n",
    "# df_tuned_alps2.loc[df_tuned_alps2['Parameter'] == 'lambda', df_tuned_alps2.columns != 'Parameter'] *= -1\n",
    "# df_tuned_alps2.set_index(df_tuned_alps2.columns[0], inplace=True)\n",
    "# df_tuned_alps2.sort_index(axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# params = ['Topt','T_crit', 'T_mult', 'lambda', 'PAR0', 'beta','alpha1', 'alpha2', 'gamma', 'theta1', 'theta2', 'theta3']\n",
    "# colors = sns.color_palette(\"husl\", len(dfs))\n",
    "# markers = ['o', 's', '^', 'D', 'P', 'X', 'p', 'H', 'v']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(3, 4, figsize=(15, 8))  # Increase width of plots\n",
    "\n",
    "# for i, (param, ax) in enumerate(zip(params, axes.flat)):\n",
    "#     for j, (df, marker) in enumerate(zip(dfs, markers)):\n",
    "#         citation_name = df.index.name\n",
    "#         ax.scatter(df.columns, df.loc[param], marker=marker, label=citation_name, color=colors[j])\n",
    "#         ax.tick_params(axis='x', rotation=45)\n",
    "#         ax.grid(True)\n",
    "#     # Plot df_tuned_alps using thick black horizontal line as a marker\n",
    "#     ax.scatter(df_tuned_alps.columns, df_tuned_alps.loc[param], marker='*', color='black', label='alps_R24', linewidth=2)  # Increase linewidth for df_tuned_alps\n",
    "#     ax.scatter(df_tuned_alps2.columns, df_tuned_alps2.loc[param], marker='*', color='red', label='europe_R24', linewidth=2)  # Increase linewidth for df_tuned_alps\n",
    "#     ax.tick_params(axis='x', rotation=45)\n",
    "#     ax.set_title(param, fontsize=font_size)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=font_size-2)\n",
    "\n",
    "# # Add a legend on the right side\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=font_size)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     \"compare_params_to_literature_\"\n",
    "#     + VPRM_old_or_new\n",
    "#     + \"_\"\n",
    "#     + run_ID\n",
    "#     + \".eps\",\n",
    "#     dpi=300,\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
